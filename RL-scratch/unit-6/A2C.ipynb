{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "import time\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 6\n",
    "#tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "#env = gym.make('MountainCar-v0')\n",
    "\n",
    "env.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Action Space: {}\".format(env.action_space))\n",
    "print(\"State space: {}\".format(env.observation_space))\n",
    "\n",
    "# An episode a full game\n",
    "train_episodes = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_actor_torch(state_shape, action_shape):\n",
    "    model = nn.Sequential(OrderedDict([\n",
    "                          ('linear1', nn.Linear(state_shape, 24)),\n",
    "                          ('linear2', nn.Linear(state_shape, 24)),\n",
    "                          ('linear3', nn.Linear(state_shape, 24)),          \n",
    "                        ]))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_actor(state_shape, action_shape):\n",
    "    learning_rate = 0.001\n",
    "    init = tf.keras.initializers.HeUniform()\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(24, input_shape=state_shape, activation=tf.keras.layers.LeakyReLU(), kernel_initializer=init))\n",
    "    model.add(keras.layers.Dense(12, activation=tf.keras.layers.LeakyReLU(), kernel_initializer=init))\n",
    "    model.add(keras.layers.Dense(action_shape, activation='softmax', kernel_initializer=init))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_critic(state_shape, output_shape):\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    init = tf.keras.initializers.HeUniform()\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(24, input_shape=state_shape, activation=tf.keras.layers.LeakyReLU(), kernel_initializer=init))\n",
    "    model.add(keras.layers.Dense(12, activation=tf.keras.layers.LeakyReLU(), kernel_initializer=init))\n",
    "    model.add(keras.layers.Dense(output_shape, activation='linear', kernel_initializer=init))\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_action(action, n_actions):\n",
    "    \n",
    "    encoded = np.zeros(n_actions, np.float32)\n",
    "    encoded[action] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_episodes):\n",
    "    # X = states, y = actions\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    actor = create_actor(env.observation_space.shape, env.action_space.n)\n",
    "    critic = create_critic(env.observation_space.shape, 1)\n",
    "\n",
    "    for episode in range(train_episodes):\n",
    "        total_training_rewards = 0\n",
    "\n",
    "        # Reset environment and get initial state\n",
    "        observation = env.reset()\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            if True:\n",
    "                env.render()\n",
    "\n",
    "            # model dims are (batch, env.observation_space.n)\n",
    "            observation_reshaped = observation.reshape([1, observation.shape[0]])\n",
    "            action_probs = actor.predict(observation_reshaped).flatten()\n",
    "            \n",
    "            # Note we're sampling from the prob distribution instead of using argmax\n",
    "            action = np.random.choice(env.action_space.n, 1, p=action_probs)[0]\n",
    "            encoded_action = one_hot_encode_action(action, env.action_space.n)\n",
    "\n",
    "            next_observation, reward, done, info = env.step(action)\n",
    "            next_observation_reshaped = next_observation.reshape([1, next_observation.shape[0]])\n",
    "\n",
    "\n",
    "            value_curr = np.asscalar(np.array(critic.predict(observation_reshaped)))\n",
    "            value_next = np.asscalar(np.array(critic.predict(next_observation_reshaped)))\n",
    "\n",
    "\n",
    "            # Fit on the current observation\n",
    "            discount_factor = .7\n",
    "            TD_target = reward + (1 - done) * discount_factor * value_next\n",
    "            advantage = critic_target = TD_target - value_curr\n",
    "\n",
    "            print(np.around(action_probs, 2), np.around(value_next - value_curr, 3), 'Advantage:', np.around(advantage, 2))\n",
    "            \n",
    "            advantage_reshaped = np.vstack([advantage])\n",
    "            TD_target = np.vstack([TD_target])\n",
    "            critic.train_on_batch(observation_reshaped, TD_target)\n",
    "            #critic.fit(observation_reshaped, TD_target, verbose=0)\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unit-8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
